# =============================================================================
# Oasis Crypto Trade - Pytest Configuration
# =============================================================================
# Comprehensive testing configuration for the Oasis trading system
# 
# Features:
# - Test discovery and organization
# - Coverage reporting
# - Performance monitoring
# - Async testing support
# - Custom markers for test categorization
# - Logging configuration
# =============================================================================

[tool:pytest]

# =============================================================================
# TEST DISCOVERY
# =============================================================================

# Minimum version required
minversion = 7.0

# Test discovery paths
testpaths = 
    tests
    apps/*/tests
    libs/*/tests

# Python files to consider as tests
python_files = 
    test_*.py
    *_test.py
    testing/test_*.py

# Python classes to consider as test classes
python_classes = 
    Test*
    *Tests
    *TestCase

# Python functions to consider as test functions
python_functions = 
    test_*

# =============================================================================
# TEST EXECUTION OPTIONS
# =============================================================================

# Add command-line options
addopts = 
    -ra
    -q
    --strict-markers
    --strict-config
    --tb=short
    --cov=apps
    --cov=libs
    --cov-report=term-missing
    --cov-report=html:htmlcov
    --cov-report=xml
    --cov-fail-under=80
    --durations=10
    --disable-warnings
    --import-mode=importlib

# Treat warnings as errors (can be overridden per test)
filterwarnings =
    error
    ignore::UserWarning
    ignore::DeprecationWarning:pkg_resources.*
    ignore::DeprecationWarning:distutils.*
    ignore::PendingDeprecationWarning
    ignore::pytest.PytestUnraisableExceptionWarning
    ignore:.*unclosed.*:ResourceWarning
    ignore:.*unclosed.*ssl.SSLSocket.*:ResourceWarning

# =============================================================================
# ASYNC TESTING
# =============================================================================

# Pytest-asyncio configuration
asyncio_mode = auto

# =============================================================================
# CUSTOM MARKERS
# =============================================================================

markers =
    # Test categories by scope
    unit: Unit tests - test individual functions/classes in isolation
    integration: Integration tests - test interaction between components
    e2e: End-to-end tests - test complete workflows
    
    # Test categories by speed
    slow: Slow tests (>1 second) - excluded by default in fast test runs
    fast: Fast tests (<1 second) - default for continuous integration
    
    # Test categories by external dependencies
    external: Tests requiring external services (exchanges, APIs)
    database: Tests requiring database connection
    cache: Tests requiring Redis cache
    messaging: Tests requiring Kafka message queue
    
    # Test categories by domain
    trading: Trading engine and strategy tests
    market_data: Market data processing tests
    risk: Risk management tests
    analytics: Analytics and reporting tests
    ui: User interface tests
    api: API endpoint tests
    
    # Test categories by ML/AI
    ml: Machine learning model tests
    backtesting: Backtesting and historical analysis tests
    
    # Test categories by performance
    benchmark: Performance benchmark tests
    load: Load testing
    stress: Stress testing
    memory: Memory usage tests
    
    # Test categories by security
    security: Security-related tests
    auth: Authentication and authorization tests
    
    # Test categories by environment
    development: Development-only tests
    staging: Staging environment tests
    production: Production environment tests (read-only)
    
    # Test categories by criticality
    critical: Critical functionality tests - must pass for releases
    regression: Regression tests for known issues
    smoke: Smoke tests - basic functionality verification
    
    # Test categories by special requirements
    requires_gpu: Tests requiring GPU acceleration
    requires_exchange_api: Tests requiring exchange API credentials
    requires_live_data: Tests requiring live market data

# =============================================================================
# COVERAGE CONFIGURATION
# =============================================================================

# Files to include in coverage
[coverage:run]
source = apps, libs
omit = 
    */tests/*
    */test_*.py
    */__pycache__/*
    */migrations/*
    */venv/*
    */env/*
    */.pytest_cache/*
    */node_modules/*
    */static/*
    */media/*
    */locale/*
    manage.py
    setup.py
    conftest.py

# Coverage reporting
[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    if self.debug:
    if settings.DEBUG
    raise AssertionError
    raise NotImplementedError
    if 0:
    if __name__ == .__main__.:
    class .*\bProtocol\):
    @(abc\.)?abstractmethod

# Coverage HTML report configuration
[coverage:html]
directory = htmlcov
title = Oasis Crypto Trade - Test Coverage Report

# Coverage XML report (for CI/CD)
[coverage:xml]
output = coverage.xml

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# Configure logging for tests
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] [%(name)s] %(message)s (%(filename)s:%(lineno)d)
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Log file configuration
log_file = tests/logs/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] [%(name)s] %(message)s (%(filename)s:%(lineno)d)
log_file_date_format = %Y-%m-%d %H:%M:%S

# Disable specific loggers during testing
log_auto_indent = true

# =============================================================================
# PYTEST-XDIST (Parallel Testing)
# =============================================================================

# Number of parallel workers (auto = number of CPUs)
# Can be overridden with: pytest -n auto
addopts_dist = -n auto

# =============================================================================
# TEMPORARY DIRECTORY CONFIGURATION  
# =============================================================================

# Custom temporary directory base
tmp_path_retention_count = 3
tmp_path_retention_policy = failed

# =============================================================================
# DJANGO-STYLE CONFIGURATION (if needed for future web components)
# =============================================================================

# Django settings (commented out - uncomment if using Django)
# DJANGO_SETTINGS_MODULE = oasis_crypto_trade.settings.testing
# django_find_project = false

# =============================================================================
# PYTEST PLUGINS
# =============================================================================

# Required plugins (installed automatically with poetry)
required_plugins =
    pytest-asyncio>=0.21.0
    pytest-cov>=4.0.0
    pytest-mock>=3.10.0
    pytest-xdist>=3.0.0
    pytest-benchmark>=4.0.0

# =============================================================================
# ENVIRONMENT VARIABLES FOR TESTING
# =============================================================================

# Environment variables to set for all tests
env = 
    OASIS_TESTING = true
    ENVIRONMENT = testing
    DEBUG = false
    LOG_LEVEL = DEBUG
    
    # Database settings for testing
    POSTGRES_DB = oasis_test_db
    REDIS_DB = 1
    
    # Disable external services for unit tests
    DISABLE_EXTERNAL_APIS = true
    MOCK_EXCHANGE_APIS = true
    
    # Security settings for testing
    SECRET_KEY = test_secret_key_not_for_production
    JWT_SECRET_KEY = test_jwt_secret_key_not_for_production
    
    # Performance settings for testing
    CACHE_TTL = 60
    REQUEST_TIMEOUT = 5

# =============================================================================
# CUSTOM TEST COLLECTION
# =============================================================================

# Custom test collection rules
collect_ignore = [
    "setup.py",
    "conftest.py",
    "migrations",
    ".pytest_cache",
    "__pycache__",
    ".git",
    ".venv",
    "venv",
    "env",
    "node_modules",
    "static",
    "media"
]

# Files to never collect as tests
collect_ignore_glob = [
    "**/migrations/**",
    "**/node_modules/**",
    "**/__pycache__/**",
    "**/*.egg-info/**"
]

# =============================================================================
# FIXTURE CONFIGURATION
# =============================================================================

# Default fixture scope
# Can be overridden per fixture with @pytest.fixture(scope="...")
default_fixture_scope = function

# =============================================================================
# TEST PARAMETRIZATION
# =============================================================================

# Generate test IDs for parametrized tests
def pytest_make_parametrize_id(config, val, argname):
    """
    Generate readable test IDs for parametrized tests.
    """
    if isinstance(val, (dict, list)):
        return f"{argname}={len(val)}_items"
    elif isinstance(val, str):
        return f"{argname}={val[:20]}"
    else:
        return f"{argname}={val}"

# =============================================================================
# EXAMPLE USAGE
# =============================================================================

# Basic test run:
# pytest

# Run specific marker:
# pytest -m "unit"
# pytest -m "unit and not slow"
# pytest -m "integration or e2e"

# Run with coverage:
# pytest --cov=apps --cov=libs --cov-report=html

# Run in parallel:
# pytest -n auto

# Run with benchmarks:
# pytest --benchmark-only

# Skip slow tests:
# pytest -m "not slow"

# Run only trading tests:
# pytest -m "trading"

# Run tests with specific output:
# pytest -v --tb=long

# Debug mode:
# pytest -s --pdb

# =============================================================================
# INTEGRATION WITH MAKEFILE
# =============================================================================

# The following commands should be available in Makefile:
# make test              -> pytest
# make test-unit         -> pytest -m "unit"
# make test-integration  -> pytest -m "integration"  
# make test-e2e          -> pytest -m "e2e"
# make test-fast         -> pytest -m "not slow"
# make test-trading      -> pytest -m "trading"
# make coverage          -> pytest --cov-report=html